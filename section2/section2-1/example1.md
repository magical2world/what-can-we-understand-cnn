#### 2.1.1 神经网络

一个典型的神经网络结构一般包括一个输入层x，一个输出层y，及一系列包含多个神经元的隐藏层h，如图2.1所示。通常情况下，每一层隐藏层会接收前一层神经元的所有输入，并对输入进行加权求和，之后在对输入的结果进行非线性变换：


$$
h_{j}=F\left ( b_{j}+\sum_{i} w_{ij}x_{i}\right)
$$


其中$$w_{ij}$$是控制输入输出单元之间的连接强度的权重，b\_j是隐藏单元的增益，而F\(.\)是一个非线性函数，如sigmoid函数。

![](/assets/1536889663%281%29.png)
<center>图2.1 一个典型的神经网络架构</center>

神经网络可以被看为是Rosenblatt感知机或多层感知机的现代化案例。虽然神经网络已经出现很多年了，但是直到最近它才被重视起来。导致神经网络知道现在才被重视的原因主要有以下几点，1、单层感知机无法实现一些简单的操作，如异或操作（XOR），直到提出多层感知机这一问题才被解决；2、在误差反向传递算法提出前，神经网络没有一套合适的训练方法；然而多层神经网络另一个很大的问题是它有很多参数，这就导致了需要很多的数据及很大的运算资源来对对参数进行训练。
深度学习中的一次重大的飞跃是基于受限制玻尔兹曼机（RBM）的逐层无监督预训练。受限制玻尔兹曼机可以看做是一个两层的神经网络，出于受限的原因，它仅有前馈连接。在图像识别中，基于无监督学习训练RBM的策略可以分为3步：1、对于每个像素，从随机初始化的权重$$w_{ij}$$及偏置$$b_{j}$$,每个隐藏层单元$$h_{j}$$
