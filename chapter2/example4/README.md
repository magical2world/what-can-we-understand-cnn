#2.4 本章综述
层级表示在计算机视觉中总是扮演着重要的角色。事实上，即使是常用的手工提取特征方法如尺度不变特性（SIFT，[99]）也可以被视为一个浅层的层级结构，放宽松的讲，它可以被解释为一个卷积层后面加上一个池化层。此外，在卷积神经网络之前的最先进的识别系统主要是通过手工提取特征然后加上空间池化层后再加上一个分类器进行识别（如[39]），这也可以被看做是一个层级表示方法。现在的层级结构利用一些学习方法将数据的层级表示变得更深，从而替代了传统的手工提取特征的方法。对于计算机视觉来说，卷积神经网络这种特殊的结构更是让其成为了最具吸引力的结构。
总的来说，虽然关于多层网络的文献很多，且每个都提倡一种架构优于另一种架构，然而一些通用的“最佳实践应用”已经出现。主要的例子包括：大多数框架都依赖于4个最基本的模块（如卷积、正则化、标准化、池化），在深层结构中使用更小的卷积核进行抽象可以减少参数量，残差连接的使用可以有效地对抗梯度消失现象。更普遍的是，这些文献都同意更好的表示来自于输入是分层的，正如前面的一些成果所述[119]。
重要的是，虽然这些网络在计算机视觉应用中达到了具有竞争力的结果，但是它们还是有很多缺点：学习到的表示很难让人理解到确切的性质，它们需要大量的数据进行训练，缺乏精确地性能判定方法及缺乏一套选择超参数的明确规则。这些选择包括滤波器大小、非线性、池化函数及参数、层数、架构本身的选择。在卷积神经网络的构架模块中，如何对这些超参数进行选择将在下一章进行讨论。
