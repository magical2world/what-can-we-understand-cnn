# 目前的卷积神经网络的一些主流架构
使卷积神经网络得到重新复兴的当属Krishevsky的AlexNet[88]。AlexNet在当时成功的打破了ImageNet物体识别的记录。它总共由8层，其中5层卷积及3层全连接层，如图2.8所示。
AlexNet提出了一些架构设计的方向，这使得可以使用随机梯度下降法可以高效地训练网络。其中有4点对AlexNet的成功起了关键的作用。1、AlexNet使用ReLU激活函数来代替其他的饱和非线性函数如之前的最先进的一些卷积神经网络（如LeNet[91]）所使用的sigmoid激活函数。ReLU的使用在一定程度上减轻了梯度消失的效果且提升了网络的训练速度。2、由于在网络的全连接层有着大量的参数，AlexNet使用了dropout（最先在文献[136]中被提出来），来减少过拟合的影响。AlexNet中使用的dropout通过随机的降低（或者说是置为0）给定层的参数的占比。该技术使得在每次训练时的网络结构都有所不同而且在每次训练中都人为的减少了所要学习的参数，这在一定程度上打破了各个单元之间的联系从而防止了过拟合。3、AlexNet通过使用数据增强技术来提高了网络的不变性的能力。例如，网络不仅仅在原始数据集上进行训练，还要在翻转及光照变换后改变的图像上进行训练。4、AlexNet使用了一些技术使得整个训练过程更快速，例如使用momentum优化算法及设置学习率随着训练过程而逐渐降低。
AlexNet的出现导致通过可视化来了解网络是如何学习的论文数量激增，如所谓的DeConvNet[154]，或者是对各种框架的系统探索[22,23]。
